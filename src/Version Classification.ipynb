{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00d078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cd7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bible versions and add version column\n",
    "asv = pd.read_csv('t_asv.csv')\n",
    "asv['Version'] = 'asv'\n",
    "bbe = pd.read_csv('t_bbe.csv')\n",
    "bbe['Version'] = 'bbe'\n",
    "dby = pd.read_csv('t_dby.csv', encoding=\"ISO-8859-1\")\n",
    "dby['Version'] = 'dby'\n",
    "kjv = pd.read_csv('t_kjv.csv')\n",
    "kjv['Version'] = 'kjv'\n",
    "wbt = pd.read_csv('t_wbt.csv')\n",
    "wbt['Version'] = 'wbt'\n",
    "web = pd.read_csv('t_web.csv')\n",
    "web['Version'] = 'web'\n",
    "ylt = pd.read_csv('t_ylt.csv')\n",
    "ylt['Version'] = 'ylt'\n",
    "versions = [asv, bbe, dby, kjv, wbt, web, ylt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "579189fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "allVersions = pd.concat(versions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e71d4dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217719"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See number of verses initially in allVersions\n",
    "len(allVersions.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b4d962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allVersionsNoDuplicates = allVersions.drop_duplicates(subset=['t'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa49cded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186759"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See number of verses without duplicates\n",
    "len(allVersionsNoDuplicates.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5ecd7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8577983547600347"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many non duplicate verses there were as a percentage \n",
    "len(allVersionsNoDuplicates.index) / len(allVersions.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcf2cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3753  188 2416  184  158  805 1310]\n",
      " [  10 9832   31    1    3   42  108]\n",
      " [1579  304 4664   71  158 1290 1574]\n",
      " [2568  105 1571  826  288  499  787]\n",
      " [1437  193 1851  169 1411 1039  785]\n",
      " [ 266  474  748   14   85 7513  388]\n",
      " [ 352  219  789   26   48  398 8301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         asv       0.38      0.43      0.40      8814\n",
      "         bbe       0.87      0.98      0.92     10027\n",
      "         dby       0.39      0.48      0.43      9640\n",
      "         kjv       0.64      0.12      0.21      6644\n",
      "         wbt       0.66      0.20      0.31      6885\n",
      "         web       0.65      0.79      0.71      9488\n",
      "         ylt       0.63      0.82      0.71     10133\n",
      "\n",
      "    accuracy                           0.59     61631\n",
      "   macro avg       0.60      0.55      0.53     61631\n",
      "weighted avg       0.60      0.59      0.56     61631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run on all versions without duplicates at once NB\n",
    "# Using language processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = allVersionsNoDuplicates['t']\n",
    "y = allVersionsNoDuplicates['Version']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Na√Øve Bayes:\n",
    "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf_nb.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "predictions = text_clf_nb.predict(X_test)\n",
    "\n",
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfc1832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3287  137 1592 1448  778  611  889]\n",
      " [  23 9643   54    1   21  126  106]\n",
      " [1558  274 4054  647  908  995 1218]\n",
      " [1395   63  589 2909 1005  269  411]\n",
      " [ 638  143  764  689 3711  655  521]\n",
      " [ 339  392  546  116  410 7554  230]\n",
      " [ 357  176  560  231  248  247 8093]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         asv       0.43      0.38      0.40      8742\n",
      "         bbe       0.89      0.97      0.93      9974\n",
      "         dby       0.50      0.42      0.46      9654\n",
      "         kjv       0.48      0.44      0.46      6641\n",
      "         wbt       0.52      0.52      0.52      7121\n",
      "         web       0.72      0.79      0.75      9587\n",
      "         ylt       0.71      0.82      0.76      9912\n",
      "\n",
      "    accuracy                           0.64     61631\n",
      "   macro avg       0.61      0.62      0.61     61631\n",
      "weighted avg       0.62      0.64      0.63     61631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run on all versions without duplicates at once LSVC\n",
    "# Using language processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = allVersionsNoDuplicates['t']\n",
    "y = allVersionsNoDuplicates['Version']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "\n",
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b9d418d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15138\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3449  152 1802 1105  792  617  897]\n",
      " [  27 9521   84    8   34  182  171]\n",
      " [1396  277 4339  526  889 1025 1188]\n",
      " [1469  109  714 2636  901  339  476]\n",
      " [ 613  212  888  428 3602  675  467]\n",
      " [ 255  450  583   69  365 7490  276]\n",
      " [ 391  163  629  160  280  351 8159]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         asv       0.45      0.39      0.42      8814\n",
      "         bbe       0.87      0.95      0.91     10027\n",
      "         dby       0.48      0.45      0.46      9640\n",
      "         kjv       0.53      0.40      0.46      6644\n",
      "         wbt       0.52      0.52      0.52      6885\n",
      "         web       0.70      0.79      0.74      9488\n",
      "         ylt       0.70      0.81      0.75     10133\n",
      "\n",
      "    accuracy                           0.64     61631\n",
      "   macro avg       0.61      0.62      0.61     61631\n",
      "weighted avg       0.62      0.64      0.63     61631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run on all versions without duplicates at once LR\n",
    "# Using language processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = allVersionsNoDuplicates['t']\n",
    "y = allVersionsNoDuplicates['Version']\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression:\n",
    "text_clf_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "text_clf_lr.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lr.predict(X_test)\n",
    "\n",
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89ba3266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of unique verses for version asv: 0.8515898787898274\n",
      "Percent of unique verses for version bbe: 0.9733144712728675\n",
      "Percent of unique verses for version dby: 0.9383903019389691\n",
      "Percent of unique verses for version kjv: 0.6485548017876089\n",
      "Percent of unique verses for version wbt: 0.6781328361087893\n",
      "Percent of unique verses for version web: 0.9313227445180374\n",
      "Percent of unique verses for version ylt: 0.9833135067356846\n"
     ]
    }
   ],
   "source": [
    "# See what percentage of duplicates each version had\n",
    "versionStrings = ['asv', 'bbe', 'dby', 'kjv', 'wbt', 'web', 'ylt']\n",
    "for v in versionStrings:\n",
    "    numUnique = len(allVersionsNoDuplicates.loc[allVersionsNoDuplicates['Version'] == v]) / len(allVersions.loc[allVersions['Version'] == v])\n",
    "    print(\"Percent of unique verses for version \" + v + \": \" + str(numUnique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d4ef3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove kjv and wbt because they have the most duplicates\n",
    "allVersionsNoDuplicatesNoKJV = allVersionsNoDuplicates[allVersionsNoDuplicates.Version != 'kjv']\n",
    "allVersionsNoDuplicatesNoKJVWBT = allVersionsNoDuplicatesNoKJV[allVersionsNoDuplicatesNoKJV.Version != 'wbt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e75f083c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4507  127 1641  995  621  836]\n",
      " [  26 9746   54   26  116  109]\n",
      " [2025  231 4231 1069  962 1167]\n",
      " [ 806  149  725 4070  573  533]\n",
      " [ 460  387  566  408 7561  251]\n",
      " [ 515  158  634  310  252 8127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         asv       0.54      0.52      0.53      8727\n",
      "         bbe       0.90      0.97      0.93     10077\n",
      "         dby       0.54      0.44      0.48      9685\n",
      "         wbt       0.59      0.59      0.59      6856\n",
      "         web       0.75      0.78      0.77      9633\n",
      "         ylt       0.74      0.81      0.77      9996\n",
      "\n",
      "    accuracy                           0.70     54974\n",
      "   macro avg       0.68      0.69      0.68     54974\n",
      "weighted avg       0.69      0.70      0.69     54974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run on all versions without duplicates at once LSVC No KJV\n",
    "# Using language processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = allVersionsNoDuplicatesNoKJV['t']\n",
    "y = allVersionsNoDuplicatesNoKJV['Version']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "\n",
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2db307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4974  135 1880  753  936]\n",
      " [  37 9583   48  134  114]\n",
      " [2282  259 4796 1112 1307]\n",
      " [ 557  356  674 7705  279]\n",
      " [ 566  179  711  291 8345]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         asv       0.59      0.57      0.58      8678\n",
      "         bbe       0.91      0.97      0.94      9916\n",
      "         dby       0.59      0.49      0.54      9756\n",
      "         web       0.77      0.81      0.79      9571\n",
      "         ylt       0.76      0.83      0.79     10092\n",
      "\n",
      "    accuracy                           0.74     48013\n",
      "   macro avg       0.72      0.73      0.73     48013\n",
      "weighted avg       0.73      0.74      0.73     48013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run on all versions without duplicates at once LSVC No KJV WBT\n",
    "# Using language processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = allVersionsNoDuplicatesNoKJVWBT['t']\n",
    "y = allVersionsNoDuplicatesNoKJVWBT['Version']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Linear SVC:\n",
    "text_clf_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "text_clf_lsvc.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "predictions = text_clf_lsvc.predict(X_test)\n",
    "\n",
    "# Report the confusion matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828fc199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
